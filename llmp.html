<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@500;700&display=swap"
      rel="stylesheet"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="32x32"
      href="./assets/images/favicon.png"
    />
    <link rel="stylesheet" href="style.css" />
    <title>Portfolio - My Work</title>
  </head>
  <body>
    <header class="header">
      <h2 class="visually-hidden">Header</h2>
      <div class="wrapper">
        <nav class="header__nav">
          <h2 class="visually-hidden">Navigation</h2>
          <a href="https://prnz82.github.io/portfolio/" class="header__home">
            pranshul<br>
  <span class="header__email">prnza82@gmail.com</span>
            <span class="visually-hidden">(to home page)</span>
          </a>
          
        </nav>
      </div>
    </header>

    <main id="main"><br><br>
      <section class="hero">
        <div class="wrapper hero__wrapper bottom-border">
          <div class="hero__content">
            
          
            
            <div class="hero__text">
              <p> <ul>
                
                <li>Designed a 3-stage multimodal reasoning orchestration pipeline that transforms raw image/audio inputs into intent-aligned, context-aware textual outputs</li>

<li>Built dual-modality ingestion (image + audio) with automatic type detection and routing</li>

<li>Implemented modality reduction layer to convert raw binary signals (vision/audio) into high-fidelity textual representations for downstream reasoning</li>

<li>Added an intermediate analytical reasoning layer to normalize outputs, suppress hallucinations, correct OCR/ASR artifacts, and extract verified entities and facts</li>

<li>Engineered a multi-intent synthesis engine supporting distinct processing pathways (Describe, Technical Analysis, Simplify, Summarize) with controlled tone, vocabulary, and output constraints</li>

<li>Designed intent-aware prompt orchestration, ensuring deterministic adherence to user-selected cognitive objectives rather than single-shot LLM responses</li>

<li>Integrated real-time end-to-end latency instrumentation, measuring full pipeline execution time (upload â†’ final render) to identify orchestration bottlenecks</li>
<li>Implemented token usage estimation per intent pathway, enabling comparative analysis of computational cost across reasoning strategies</li>
<li>Added in-memory request-level caching to eliminate redundant multimodal processing for identical inputs, significantly reducing recomputation and perceived latency</li>


                
              </ul>
          
              
            </div>
          </div>
        </div>
      </section>

      

     
    </main>

 
  </body>
</html>
